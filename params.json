{
  "name": "HBase Object Mapper",
  "tagline": " A Java-annotation based object mapper that helps convert your bean-like objects to HBase row data (and vice-versa). For use in:  [1] Hadoop MapReduce jobs that read from and/or write to HBase tables (and their unit tests) [2] Defining Data Access Objects for HBase entities for random READ/WRITE operations",
  "body": "# HBase Object Mapper\r\n\r\n## Introduction\r\nThis compact utility library is an annotation based *object mapper* for HBase (written in Java) that helps you:\r\n\r\n* convert objects of your bean-like classes to HBase rows and vice-versa\r\n * for use in Hadoop MapReduce jobs that read from and/or write to HBase tables\r\n * and write efficient unit-tests for `Mapper` and `Reducer` classes\r\n* define *data access objects* for entities that map to HBase rows\r\n * for random single/range/bulk access of rows of an HBase table\r\n\r\n## Usage\r\nLet's say you've an HBase table `citizens` with row-key format of `country_code#UID`. Now, let's say your table is created with two column families `main` and `optional`, which may have columns like `uid`, `name`, `salary` etc.\r\n\r\nThis library enables to you represent your HBase table as a bean-like class, as below:\r\n\r\n```java\r\n@HBTable(\"citizens\")\r\npublic class Citizen implements HBRecord<String> {\r\n    @HBRowKey\r\n    private String countryCode;\r\n    @HBRowKey\r\n    private Integer uid;\r\n    @HBColumn(family = \"main\", column = \"name\")\r\n    private String name;\r\n    @HBColumn(family = \"optional\", column = \"age\")\r\n    private Short age;\r\n    @HBColumn(family = \"optional\", column = \"salary\")\r\n    private Integer sal;\r\n    @HBColumn(family = \"optional\", column = \"flags\")\r\n    private Map<String, Integer> extraFlags;\r\n    @HBColumn(family = \"optional\", column = \"dependents\")\r\n    private Dependents dependents;\r\n    @HBColumnMultiVersion(family = \"optional\", column = \"phone_number\")\r\n    private NavigableMap<Long, Integer> phoneNumber; // Multi-versioned column. This annotation enables you to fetch multiple versions of column values\r\n\r\n    public String composeRowKey() {\r\n        return String.format(\"%s#%d\", countryCode, uid);\r\n    }\r\n\r\n    public void parseRowKey(String rowKey) {\r\n        String[] pieces = rowKey.split(\"#\");\r\n        this.countryCode = pieces[0];\r\n        this.uid = Integer.parseInt(pieces[1]);\r\n    }\r\n    \r\n    // Constructors, getters and setters\r\n} \r\n```\r\nwhere, following things are provided:\r\n\r\n* Name of the HBase table (`citizens`) that the class maps to, using `HBTable` annotation\r\n* Data type to map row keys to (`String`) as generic type parameter for `HBRecord` interface\r\n* Logics for conversion of HBase row key to Java types and vice-versa by implmenting `parseRowKey` and `composeRowKey` methods\r\n* Names of columns and their column families using `HBColumn` annotation\r\n\r\nThis library enables you to represent rows of `citizens` HBase table as instances of `Citizen` class.\r\n\r\nSee source files [Citizen.java](./src/test/java/com/flipkart/hbaseobjectmapper/entities/Citizen.java) and [Employee.java](./src/test/java/com/flipkart/hbaseobjectmapper/entities/Employee.java) for detailed examples.\r\n\r\nNow, for above definition of your `Citizen` class,\r\n\r\n* you can use methods in `HBObjectMapper` class to convert `Citizen` objects to HBase's `Put` and `Result` objects and vice-versa\r\n* you can inherit from class `AbstractHBDAO` that contains methods like `get` (for random single/bulk/range access of rows), `persist` (for writing rows) and `delete` (for deleting rows)\r\n\r\n## MapReduce use-cases\r\n\r\n### Mapper\r\nIf your MapReduce job is reading from an HBase table, in your `map()` method, HBase's `Result` object can be converted to object of your bean-like class using below method: \r\n\r\n```java\r\n<T extends HBRecord> T readValue(ImmutableBytesWritable rowKey, Result result, Class<T> clazz)\r\n```\r\n\r\nFor example:\r\n\r\n```java\r\nCitizen e = hbObjectMapper.readValue(key, value, Citizen.class);\r\n```\r\nSee file [CitizenMapper.java](./src/test/java/com/flipkart/hbaseobjectmapper/mr/samples/CitizenMapper.java) for full sample code.\r\n\r\n### Reducer\r\nIf your MapReduce job is writing to an HBase table, in your `reduce()` method, object of your bean-like class can be converted to HBase's `Put` (for row contents) and `ImmutableBytesWritable` (for row key) using below methods:\r\n\r\n```java\r\nImmutableBytesWritable getRowKey(HBRecord obj)\r\n```\r\n```java\r\nPut writeValueAsPut(HBRecord obj)\r\n```\r\nFor example, below code in reducer writes your object as one HBase row with appropriate column families and columns:\r\n\r\n```java\r\nCitizen citizen = new Citizen(/*details*/);\r\ncontext.write(hbObjectMapper.getRowKey(citizen), hbObjectMapper.writeValueAsPut(citizen));\r\n```\r\n\r\nSee file [CitizenReducer.java](./src/test/java/com/flipkart/hbaseobjectmapper/mr/samples/CitizenReducer.java) for full sample code.\r\n\r\n### Unit-test for Mapper\r\nIf your MapReduce job is reading from an HBase table, you would want to unit-test your `map()` method as below.\r\n\r\nObject of your bean-like class can be converted to HBase's `Put` (for row contents) and `ImmutableBytesWritable` (for row key) using below methods:\r\n\r\n```java\r\nImmutableBytesWritable getRowKey(HBRecord obj)\r\n```\r\n```java\r\nResult writeValueAsResult(HBRecord obj)\r\n```\r\nBelow is an example of unit-test of a mapper using [MRUnit](https://mrunit.apache.org/):\r\n\r\n```java\r\nCitizen citizen = new Citizen(/*params*/);\r\nmapDriver\r\n    .withInput(\r\n            hbObjectMapper.getRowKey(citizen),\r\n            hbObjectMapper.writeValueAsResult(citizen)\r\n    )\r\n    .withOutput(Util.strToIbw(\"key\"), new IntWritable(citizen.getAge()))\r\n    .runTest();\r\n```\r\n\r\n\r\nSee file [TestCitizenMapper.java](./src/test/java/com/flipkart/hbaseobjectmapper/mr/TestCitizenMapper.java) for full sample code.\r\n\r\n### Unit-test for Reducer\r\nIf your MapReduce job is writing to an HBase table, you would want to unit-test your `reduce()` method as below.\r\n\r\nHBase's `Put` object can be converted to your bean-like object using below method:\r\n \r\n```java\r\n<T extends HBRecord> T readValue(ImmutableBytesWritable rowKeyBytes, Put put, Class<T> clazz)\r\n```\r\n\r\nBelow is an example of unit-test of a reducer using [MRUnit](https://mrunit.apache.org/):\r\n\r\n```java\r\nPair<ImmutableBytesWritable, Writable> reducerResult = reducerDriver.withInput(Util.strToIbw(\"key\"), Arrays.asList(new IntWritable(1), new IntWritable(5))).run().get(0);\r\nCitizen citizen = hbObjectMapper.readValue(reducerResult.getFirst(), (Put) reducerResult.getSecond(), Citizen.class);\r\n```\r\n\r\nSee file [TestCitizenReducer.java](./src/test/java/com/flipkart/hbaseobjectmapper/mr/TestCitizenReducer.java) for full sample code.\r\n\r\n## HBase Random Access\r\nThis library provides an abstract class to define your own *data access object*. For example you can create a *data access object* for `Citizen` class in the above example as follows:\r\n\r\n```java\r\nimport org.apache.hadoop.conf.Configuration;\r\n\r\npublic class CitizenDAO extends AbstractHBDAO<Citizen> {\r\n    \r\n    public CitizenDAO(Configuration conf) throws IOException {\r\n        super(conf);\r\n    }\r\n}\r\n```\r\n(see [CitizenDAO.java](./src/test/java/com/flipkart/hbaseobjectmapper/daos/CitizenDAO.java))\r\n\r\nOnce defined, you can access, manipulate and persist a row of `citizens` HBase table as below:\r\n\r\n```java\r\nConfiguration configuration = getConf(); // this is org.apache.hadoop.conf.Configuration\r\n\r\n// Create a data access object:\r\nCitizenDAO citizenDao = new CitizenDAO(configuration);\r\n\r\n// Fetch a row from \"citizens\" HBase table with row key \"IND#1\":\r\nCitizen pe = citizenDao.get(\"IND#1\");\r\n\r\nCitizen[] ape = citizenDao.get(new String[] {\"IND#1\", \"IND#2\"}); //bulk get\r\n\r\n// In below, note that \"IND#1\" is inclusive and \"IND#5\" is exclusive\r\nList<Citizen> lpe = citizenDao.get(\"IND#1\", \"IND#5\"); //range get\r\n\r\n// for row keys in range [\"IND#1\", \"IND#5\"), fetch 3 versions of field 'phoneNumberHistory' \r\nNavigableMap<String /* row key */, NavigableMap<Long /* timestamp */, Object /* column value */>> phoneNumberHistory \r\n\t= citizenDao.fetchFieldValues(\"IND#1\", \"IND#5\", \"phoneNumberHistory\", 3);\r\n//(bulk variant of above range method is also available)\r\n\r\npe.setPincode(560034); // change a field\r\n\r\ncitizenDao.persist(pe); // Save it back to HBase\r\n\r\ncitizenDao.delete(pe); // Delete a row by it's object reference\r\n\r\ncitizenDao.delete(\"IND#2\"); // Delete a row by it's row key\r\n// (bulk variant of delete method is also available)\r\n\r\ncitizenDao.getHBaseTable() // returns HTable instance (in case you want to directly play around) \r\n\r\n```\r\n(see [TestsAbstractHBDAO.java](./src/test/java/com/flipkart/hbaseobjectmapper/TestsAbstractHBDAO.java) for a more detailed examples)\r\n\r\n**Please note:** Since we're dealing with HBase (and not an OLTP data store), fitting an classical ORM paradigm may not make sense. So this library doesn't intend to evolve as a full-fledged ORM. However, if you do intend to use HBase via ORM, I suggest you use [Apache Phoenix](https://phoenix.apache.org/). \r\n\r\n\r\n## Limitations\r\n\r\n* Being an *object mapper*, this library works for pre-defined columns only. For example, this library doesn't provide ways to fetch:\r\n * columns matching a regular expression\r\n * (unmapped) columns of a column family\r\n* When you `get` a row by it's row-key, data for all columns (of all families) are fetched.\r\n * Workaround: If you want to selectively fetch data for given column families, use multiple classes, one for each column family\r\n\r\n\r\n## Maven\r\nAdd below entry within the `dependencies` section of your `pom.xml`:\r\n\r\n```xml\r\n<dependency>\r\n\t<groupId>com.flipkart</groupId>\r\n\t<artifactId>hbase-object-mapper</artifactId>\r\n\t<version>1.4</version>\r\n</dependency>\r\n```\r\n(See artifact details for [com.flipkart:hbase-object-mapper:1.4]((http://search.maven.org/#artifactdetails%7Ccom.flipkart%7Chbase-object-mapper%7C1.4%7Cjar)) on **Maven Central**)\r\n\r\n## How to build?\r\nTo build this project, follow below steps:\r\n\r\n * Do a `git clone` of this repository\r\n * Checkout latest stable version `git checkout v1.4`\r\n * Execute `mvn clean install` from shell\r\n\r\nCurrently, projects that use this library are running on [Hortonworks Data Platform v2.2](http://hortonworks.com/blog/announcing-hdp-2-2/) (corresponds to Hadoop 2.6 and HBase 0.98). However, if you're using a different distribution of Hadoop (like [Cloudera](http://www.cloudera.com/)) or if you are using a different version of Hadoop, you may change the versions in [pom.xml](./pom.xml) to desired ones and build the project.\r\n\r\n**Please note**: Test cases are very comprehensive - they even spin an [in-memory HBase test cluster](https://github.com/apache/hbase/blob/master/hbase-server/src/test/java/org/apache/hadoop/hbase/HBaseTestingUtility.java) to run data access related test cases (near-realworld scenario). So, build times can sometimes be longer.\r\n\r\n## Releases\r\n\r\nThe change log can be found in the [releases](../../releases) section.\r\n\r\n## Feature requests and bug reporting\r\n\r\nIf you intend to request a feature or report a bug, you may use [Github Issues for hbase-object-mapper](../../issues).\r\n\r\n## License\r\n\r\nCopyright 2016 Flipkart Internet Pvt Ltd.\r\n\r\nLicensed under the [Apache License, version 2.0](http://www.apache.org/licenses/LICENSE-2.0) (the \"License\"). You may not use this product or it's source code except in compliance with the License.\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}